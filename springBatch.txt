To pass the table name dynamically from your job configuration to the `ChunkStatisticsListener`, you can modify the listener to accept the table name as a parameter. One way to achieve this is by using Spring's dependency injection and passing the table name via job parameters.

Here's how you can modify your listener and job configuration:

### Modify `ChunkStatisticsListener`

First, modify the `ChunkStatisticsListener` to accept the table name as a parameter:

```java
import org.springframework.batch.core.ExitStatus;
import org.springframework.batch.core.StepExecution;
import org.springframework.batch.core.StepExecutionListener;
import org.springframework.batch.core.annotation.AfterChunk;
import org.springframework.batch.core.annotation.BeforeChunk;
import org.springframework.batch.core.annotation.AfterStep;
import org.springframework.batch.core.annotation.BeforeStep;
import org.springframework.batch.core.scope.context.ChunkContext;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.jdbc.core.JdbcTemplate;
import org.springframework.stereotype.Component;

@Component
public class ChunkStatisticsListener implements StepExecutionListener, ChunkListener {

    private final JdbcTemplate jdbcTemplate;
    private StepExecution stepExecution;
    private String tableName;

    public ChunkStatisticsListener(JdbcTemplate jdbcTemplate, @Value("#{jobParameters['tableName']}") String tableName) {
        this.jdbcTemplate = jdbcTemplate;
        this.tableName = tableName;
    }

    @BeforeStep
    public void beforeStep(StepExecution stepExecution) {
        this.stepExecution = stepExecution;
    }

    @AfterStep
    public ExitStatus afterStep(StepExecution stepExecution) {
        // Optional: add logic for after the step is complete
        return stepExecution.getExitStatus();
    }

    @BeforeChunk
    public void beforeChunk(ChunkContext context) {
        // Optional: add logic for before a chunk is processed
    }

    @AfterChunk
    public void afterChunk(ChunkContext context) {
        // Fetch the total count of records in the database table
        int totalCount = jdbcTemplate.queryForObject("SELECT COUNT(*) FROM " + tableName, Integer.class);

        // Fetch the count of records written in the current chunk
        int chunkCount = stepExecution.getWriteCount();

        // Log the statistics
        System.out.println("Records written in this chunk: " + chunkCount);
        System.out.println("Total records in the table: " + totalCount);
    }

    @Override
    public void afterChunkError(ChunkContext context) {
        // Optional: add logic for handling errors after a chunk
    }
}
```

### Update Job Configuration

In your job configuration, pass the table name as a job parameter:

```java
import org.springframework.batch.core.Job;
import org.springframework.batch.core.Step;
import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;
import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;
import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;
import org.springframework.batch.core.launch.support.RunIdIncrementer;
import org.springframework.batch.core.listener.JobListenerFactoryBean;
import org.springframework.batch.core.repository.JobRepository;
import org.springframework.batch.core.step.builder.StepBuilder;
import org.springframework.batch.core.step.tasklet.Tasklet;
import org.springframework.batch.core.transaction.support.TransactionTemplate;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.core.task.TaskExecutor;
import org.springframework.jdbc.datasource.DataSourceTransactionManager;

@Configuration
@EnableBatchProcessing
public class BatchConfig extends DefaultBatchConfiguration {

    @Autowired
    private JobBuilderFactory jobBuilderFactory;

    @Autowired
    private StepBuilderFactory stepBuilderFactory;

    @Autowired
    private DataSourceTransactionManager transactionManager;

    @Autowired
    private ChunkStatisticsListener chunkStatisticsListener;

    @Bean
    public Job job(JobRepository jobRepository, Step step) {
        return jobBuilderFactory.get("job")
                .incrementer(new RunIdIncrementer())
                .listener(chunkStatisticsListener)
                .start(step)
                .build();
    }

    @Bean
    @JobScope
    public Step step(JobRepository jobRepository,
                     Tasklet tasklet,
                     ChunkStatisticsListener chunkStatisticsListener,
                     @Value("#{jobParameters['tableName']}") String tableName) {
        chunkStatisticsListener.setTableName(tableName);
        return stepBuilderFactory.get("step")
                .<Map<String, Object>, Map<String, Object>>chunk(10)
                .reader(reader())
                .processor(processor())
                .writer(writer())
                .listener(chunkStatisticsListener)
                .build();
    }

    // Define reader, processor, and writer beans here
}
```

### Job Parameter

When you launch the job, ensure you pass the table name as a job parameter. This can be done via command line or programmatically:

```java
Map<String, JobParameter> parameters = new HashMap<>();
parameters.put("tableName", new JobParameter("your_table_name"));
JobParameters jobParameters = new JobParameters(parameters);

JobExecution jobExecution = jobLauncher.run(job, jobParameters);
```

### Setters for Table Name

Add a setter for `tableName` in `ChunkStatisticsListener`:

```java
public void setTableName(String tableName) {
    this.tableName = tableName;
}
```

This way, the table name is dynamically passed to the listener, and the listener will use this table name to fetch statistics after each chunk.
